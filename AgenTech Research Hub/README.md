# AgenTech Research Hub ğŸš€

> Advanced AI Research Platform with Real Internet Search & Multi-Agent Collaboration

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat&logo=FastAPI&logoColor=white)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸŒŸ Overview

AgenTech Research Hub is a powerful AI-driven research platform that performs **real internet searches** across multiple sources including DuckDuckGo, Wikipedia, Reddit, and GitHub. Built with FastAPI and featuring a modern web interface, it provides intelligent topic detection, multi-source research aggregation, and professional reporting.

## âœ¨ Key Features

- ğŸ” **Real Internet Search**: Actual web scraping from multiple sources (not mock data)
- ğŸ¯ **Intelligent Topic Detection**: Automatically categorizes research queries
- ğŸŒ **Multi-Source Research**: DuckDuckGo, Wikipedia, Reddit, GitHub integration
- ğŸ“Š **Quality Scoring**: Relevance and credibility assessment of sources
- ğŸ¨ **Professional Web UI**: Modern, responsive interface with blue corporate theme
- ğŸ³ **Docker Ready**: Complete containerization with nginx load balancing
- âš¡ **FastAPI Backend**: High-performance async API with automatic documentation
- ğŸ”„ **CORS Support**: Cross-origin requests handled seamlessly

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd "AgenTech Research Hub"

# Start with Docker Compose
docker-compose up -d

# Access the application
# Web UI: http://localhost:3000
# API Docs: http://localhost:8000/docs
# Health Check: http://localhost:3000/health
```

### Option 2: Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Start the API server
python api_server.py

# Open web UI
open web-ui/index.html
```

## ğŸ—ï¸ System Architecture

```mermaid
flowchart TB
    subgraph "User Interface"
        UI[ğŸŒ Web Interface<br/>HTML/CSS/JavaScript]
        USER[ğŸ‘¤ User Query Input]
    end
    
    subgraph "Docker Environment"
        subgraph "Nginx Proxy"
            NGINX[ğŸ”„ Nginx Reverse Proxy<br/>Port 80]
        end
        
        subgraph "API Layer"
            API[ğŸš€ FastAPI Backend<br/>Port 8000]
            HEALTH[ğŸ’š Health Endpoints]
            RESEARCH[ğŸ” Research Endpoints]
        end
        
        subgraph "Core Intelligence"
            AGENT[ğŸ¤– Research Agent<br/>AI-Powered Analysis]
            SEARCH[ğŸŒ Multi-Source Search Engine]
        end
        
        subgraph "External Data Sources"
            DUCK[ğŸ¦† DuckDuckGo Search]
            WIKI[ğŸ“š Wikipedia API]
            REDDIT[ğŸ’¬ Reddit API]
            GITHUB[ğŸ™ GitHub Search]
        end
        
        subgraph "Data Processing"
            SCORER[ğŸ“Š Quality Scoring System]
            CACHE[âš¡ Redis Cache]
            FILTER[ğŸ¯ Content Filtering]
        end
    end
    
    %% User Flow
    USER --> UI
    UI --> NGINX
    NGINX --> API
    
    %% API Processing
    API --> HEALTH
    API --> RESEARCH
    RESEARCH --> AGENT
    
    %% Research Flow
    AGENT --> SEARCH
    SEARCH --> DUCK
    SEARCH --> WIKI
    SEARCH --> REDDIT
    SEARCH --> GITHUB
    
    %% Data Processing Flow
    DUCK --> SCORER
    WIKI --> SCORER
    REDDIT --> SCORER
    GITHUB --> SCORER
    
    SCORER --> FILTER
    FILTER --> CACHE
    CACHE --> AGENT
    
    %% Response Flow
    AGENT --> RESEARCH
    RESEARCH --> API
    API --> NGINX
    NGINX --> UI
    UI --> USER
    
    %% Styling
    classDef userClass fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef apiClass fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef agentClass fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef dataClass fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef processClass fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    
    class USER,UI userClass
    class NGINX,API,HEALTH,RESEARCH apiClass
    class AGENT,SEARCH agentClass
    class DUCK,WIKI,REDDIT,GITHUB dataClass
    class SCORER,CACHE,FILTER processClass
```

## ğŸ”„ Research Workflow

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ User
    participant UI as ğŸŒ Web Interface
    participant API as ğŸš€ FastAPI
    participant Agent as ğŸ¤– Research Agent
    participant Search as ğŸ” Search Engine
    participant Sources as ğŸŒ External APIs
    participant Cache as âš¡ Redis Cache
    
    User->>UI: Enter research query
    UI->>API: POST /api/research
    API->>Agent: Process research request
    
    Agent->>Cache: Check for cached results
    alt Cache Hit
        Cache-->>Agent: Return cached data
    else Cache Miss
        Agent->>Search: Initiate multi-source search
        
        par Parallel Search
            Search->>Sources: DuckDuckGo API
            Search->>Sources: Wikipedia API
            Search->>Sources: Reddit API
            Search->>Sources: GitHub API
        end
        
        Sources-->>Search: Raw search results
        Search->>Search: Quality scoring & filtering
        Search->>Cache: Store processed results
        Search-->>Agent: Return ranked results
    end
    
    Agent->>Agent: Generate comprehensive analysis
    Agent-->>API: Research insights
    API-->>UI: JSON response
    UI-->>User: Display formatted results
```

### Components

- **FastAPI Backend**: Handles research requests and web scraping
- **Nginx Proxy**: Serves static files and proxies API calls
- **Web UI**: Modern JavaScript interface with auto-detection
- **Redis Cache**: Optional caching layer for improved performance

## ğŸ“Š Search Sources

| Source | Purpose | Data Type |
|--------|---------|-----------|
| **DuckDuckGo** | General web search | Instant answers, web results |
| **Wikipedia** | Encyclopedia articles | Structured knowledge |
| **Reddit** | Community discussions | Social insights, trends |
| **GitHub** | Code repositories | Technical documentation |

## ğŸ“ Project Structure

```
AgenTech Research Hub/
â”œâ”€â”€ ğŸ³ api_server.py                 # Main FastAPI application
â”œâ”€â”€ ğŸ³ docker-compose.yml            # Multi-container orchestration
â”œâ”€â”€ ğŸ³ Dockerfile                    # Container configuration
â”œâ”€â”€ ğŸ”§ nginx.conf                    # Reverse proxy configuration
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸš€ start_server.sh              # Launch script (Unix)
â”œâ”€â”€ ğŸ›‘ stop_server.sh               # Stop script (Unix)
â”œâ”€â”€ ğŸ§ª test_docker.sh               # Docker testing script
â”œâ”€â”€ ğŸ“– README.md                     # This documentation
â”œâ”€â”€ ğŸ“„ LICENSE                       # Project license
â”œâ”€â”€ ğŸ“ src/                          # Source code
â”‚   â”œâ”€â”€ ğŸ“ agents/                   # AI agent implementations
â”‚   â”‚   â”œâ”€â”€ ğŸ¤– researcher_agent.py   # Main research agent
â”‚   â”‚   â”œâ”€â”€ ğŸ¯ topic_detector.py     # Topic classification
â”‚   â”‚   â””â”€â”€ ğŸ“Š quality_scorer.py     # Source quality assessment
â”‚   â”œâ”€â”€ ğŸ“ api/                      # API route handlers
â”‚   â”‚   â”œâ”€â”€ ğŸŒ routes.py             # HTTP endpoints
â”‚   â”‚   â””â”€â”€ ğŸ”§ middleware.py         # CORS & error handling
â”‚   â”œâ”€â”€ ğŸ“ core/                     # Core application logic
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ config.py             # Configuration management
â”‚   â”‚   â””â”€â”€ ğŸ“‹ models.py             # Data models
â”‚   â”œâ”€â”€ ğŸ“ config/                   # Configuration files
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ settings.py           # Application settings
â”‚   â”‚   â””â”€â”€ ğŸ—„ï¸ database.py          # Database configuration
â”‚   â”œâ”€â”€ ğŸ“ crews/                    # CrewAI implementations
â”‚   â”‚   â”œâ”€â”€ ğŸ‘¥ research_crew.py      # Multi-agent coordination
â”‚   â”‚   â””â”€â”€ ğŸ“‹ crew_config.py        # Crew configuration
â”‚   â”œâ”€â”€ ğŸ“ utils/                    # Utility functions
â”‚   â”‚   â”œâ”€â”€ ğŸ”§ helpers.py            # Helper functions
â”‚   â”‚   â””â”€â”€ ğŸ“ logger.py             # Logging configuration
â”‚   â””â”€â”€ ğŸ“ workflows/                # Workflow definitions
â”‚       â”œâ”€â”€ ğŸ”„ research_workflow.py  # Main research process
â”‚       â””â”€â”€ ğŸ“Š analysis_workflow.py  # Data analysis process
â”œâ”€â”€ ğŸ“ web-ui/                       # Frontend interface
â”‚   â”œâ”€â”€ ğŸŒ index.html               # Main web interface
â”‚   â”œâ”€â”€ ğŸ¨ styles.css               # Professional styling
â”‚   â”œâ”€â”€ âš¡ script.js                # Interactive functionality
â”‚   â””â”€â”€ ğŸ“± favicon.ico              # Site icon
â”œâ”€â”€ ğŸ“ tests/                        # Test suite
â”‚   â”œâ”€â”€ ğŸ§ª test_api.py              # API endpoint tests
â”‚   â”œâ”€â”€ ğŸ¤– test_agents.py           # Agent functionality tests
â”‚   â”œâ”€â”€ ğŸ“Š test_integration.py      # Integration tests
â”‚   â””â”€â”€ ğŸ”§ conftest.py              # Test configuration
â”œâ”€â”€ ğŸ“ docs/                        # Additional documentation
â”‚   â”œâ”€â”€ ğŸ“„ project_documentation.md # Technical documentation
â”‚   â”œâ”€â”€ ğŸ“„ DOCKER_SUCCESS.md       # Docker deployment guide
â”‚   â””â”€â”€ ğŸ“„ PROJECT_CLEANUP_SUMMARY.md # Project organization notes
â”œâ”€â”€ ğŸ“ data/                        # Application data
â”‚   â”œâ”€â”€ ğŸ“ cache/                   # Cached search results
â”‚   â”œâ”€â”€ ğŸ“ logs/                    # Application logs
â”‚   â”œâ”€â”€ ğŸ“ checkpoints/             # Model checkpoints
â”‚   â”œâ”€â”€ ğŸ“ models/                  # Trained models
â”‚   â”œâ”€â”€ ğŸ“ outputs/                 # Generated outputs
â”‚   â”œâ”€â”€ ğŸ“ processed/               # Processed data
â”‚   â”œâ”€â”€ ğŸ“ raw/                     # Raw data files
â”‚   â””â”€â”€ ğŸ“ vector_db/               # Vector database
â”œâ”€â”€ ğŸ“ examples/                     # Usage examples
â”‚   â”œâ”€â”€ ğŸ“ basic_usage.py           # Basic API usage
â”‚   â”œâ”€â”€ ğŸ”„ workflow_example.py      # Workflow demonstration
â”‚   â””â”€â”€ ğŸ“Š analysis_example.py      # Analysis examples
â”œâ”€â”€ ğŸ“ logs/                        # System logs
â”‚   â”œâ”€â”€ ğŸ“‹ api.log                  # API request logs
â”‚   â”œâ”€â”€ ğŸ¤– agent.log               # Agent activity logs
â”‚   â””â”€â”€ ğŸ³ docker.log              # Container logs
â””â”€â”€ ğŸ“ scripts/                     # Utility scripts
    â”œâ”€â”€ ğŸ”§ setup.py                # Environment setup
    â”œâ”€â”€ ğŸ“Š benchmark.py            # Performance testing
    â””â”€â”€ ğŸ§¹ cleanup.py              # Cleanup utilities
```

## ğŸ¯ Features & Capabilities

### ğŸ” **Real Internet Search**
- **Live Data Scraping**: Actual web scraping from multiple sources
- **Rate Limiting**: Respectful API usage with proper delays
- **Error Handling**: Robust fallback mechanisms for failed requests
- **Quality Filtering**: Advanced content relevance scoring

### ğŸ¤– **AI-Powered Analysis**
- **Topic Detection**: Automatic categorization of research queries
- **Source Ranking**: Intelligent prioritization based on credibility
- **Content Synthesis**: Comprehensive analysis generation
- **Trend Identification**: Pattern recognition across data sources

### ğŸŒ **Professional Web Interface**
- **Responsive Design**: Mobile-friendly interface
- **Real-time Updates**: Live search progress indicators
- **Professional Styling**: Corporate blue theme
- **Auto-detection**: Smart query type recognition

### ğŸ³ **Production Ready**
- **Docker Containerization**: Easy deployment and scaling
- **Nginx Load Balancing**: High-performance request handling
- **Health Monitoring**: Comprehensive system health checks
- **Logging & Monitoring**: Detailed application insights

## ğŸ“– API Documentation

### Health Check Endpoint

```bash
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00Z",
  "version": "1.0.0"
}
```

### Research Endpoint

```bash
POST /api/research
Content-Type: application/json

{
  "query": "artificial intelligence trends 2024",
  "sources": ["duckduckgo", "wikipedia", "reddit", "github"],
  "max_results": 10
}
```

**Response:**
```json
{
  "query": "artificial intelligence trends 2024",
  "topic": "Technology",
  "results": [
    {
      "source": "duckduckgo",
      "title": "AI Trends 2024",
      "url": "https://example.com/ai-trends",
      "content": "Latest developments in AI...",
      "quality_score": 0.95,
      "relevance_score": 0.92
    }
  ],
  "summary": "Comprehensive analysis of AI trends...",
  "timestamp": "2024-01-15T10:30:00Z"
}
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false

# Search Configuration
ENABLE_DUCKDUCKGO=true
ENABLE_WIKIPEDIA=true
ENABLE_REDDIT=true
ENABLE_GITHUB=true

# Cache Configuration
REDIS_URL=redis://localhost:6379
CACHE_TTL=3600

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
REQUEST_TIMEOUT=30
```

### Docker Configuration

```yaml
# docker-compose.yml
version: '3.8'
services:
  agentech-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DEBUG=false
      - API_HOST=0.0.0.0
    
  nginx:
    image: nginx:alpine
    ports:
      - "3000:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./web-ui:/usr/share/nginx/html
```

## ğŸ§ª Testing

### Run Tests

```bash
# Install test dependencies
pip install pytest pytest-asyncio

# Run all tests
pytest tests/

# Run specific test categories
pytest tests/test_api.py -v
pytest tests/test_agents.py -v
pytest tests/test_integration.py -v

# Run with coverage
pytest --cov=src tests/
```

### Test Coverage

```bash
# Generate coverage report
pytest --cov=src --cov-report=html tests/
open htmlcov/index.html
```

## ğŸ› Troubleshooting

### Common Issues

#### Docker Issues
- **Port conflicts**: Ensure ports 3000 and 8000 are available
- **Permission errors**: Use `sudo` for Docker commands if needed
- **Container startup failures**: Check logs with `docker-compose logs`

#### API Issues
- **Slow responses**: Check internet connection and API rate limits
- **Failed searches**: Verify source availability and API keys
- **Memory issues**: Increase Docker memory allocation

#### Web Interface Issues
- **Blank page**: Check browser console for JavaScript errors
- **API connection errors**: Verify backend is running on port 8000
- **CORS issues**: Ensure proper CORS configuration in FastAPI

### Performance Optimization

```bash
# Monitor container performance
docker stats

# Check API response times
curl -w "@curl-format.txt" -o /dev/null -s "http://localhost:8000/health"

# Profile memory usage
python -m memory_profiler api_server.py
```

## ğŸ”® Future Enhancements

- **AI Model Integration**: Local LLM support for offline analysis
- **Database Storage**: Persistent storage for research history
- **User Authentication**: Multi-user support with personalized settings
- **Advanced Analytics**: Trend analysis and predictive insights
- **Mobile App**: Native mobile application development
- **API Rate Limiting**: Enhanced rate limiting and quota management

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ”— Links

- **Web UI**: <http://localhost:3000>
- **API Documentation**: <http://localhost:8000/docs>
- **Health Monitor**: <http://localhost:3000/health>

---

## ğŸ‘¨â€ğŸ’» Author & License

All code and content in this repository is for educational and personal use.

**Somesh Ramesh Ghaturle**  
MS in Data Science, Pace University

ğŸ“§ **Email:** [someshghaturle@gmail.com](mailto:someshghaturle@gmail.com)  
ğŸ™ **GitHub:** [https://github.com/somesh-ghaturle](https://github.com/somesh-ghaturle)  
ğŸ’¼ **LinkedIn:** [https://www.linkedin.com/in/someshghaturle/](https://www.linkedin.com/in/someshghaturle/)

---

### Built with â¤ï¸ using FastAPI, Docker, and Modern Web Technologies
