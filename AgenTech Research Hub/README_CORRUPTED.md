# Ag[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat&logo=FastAPI&logoColor=white)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)h Research Hub ğŸš€

> Advanced AI Research Platform with Real Internet Search & Multi-Agent Collaboration

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat&logo=FastAPI&logoColor=white)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docke## ğŸ‘¨â€---

## ğŸ‘¨â€ï¿½ğŸ’» Author & License

All code and content in this repository is for educational and personal use.

**Somesh Ramesh Ghaturle**  
MS in Data Science, Pace University

ğŸ“§ **Email:** [someshghaturle@gmail.com](mailto:someshghaturle@gmail.com)  
ğŸ™ **GitHub:** [https://github.com/somesh-ghaturle](https://github.com/somesh-ghaturle)  
ğŸ’¼ **LinkedIn:** [https://www.linkedin.com/in/someshghaturle/](https://www.linkedin.com/in/someshghaturle/)

--- License

All code and content in this repository is for educational and personal use.

**Somesh Ramesh Ghaturle**  
MS in Data Science, Pace University

ğŸ“§ **Email:** [someshghaturle@gmail.com](mailto:someshghaturle@gmail.com)  
ğŸ™ **GitHub:** [https://github.com/somesh-ghaturle](https://github.com/somesh-ghaturle)  
ğŸ’¼ **LinkedIn:** [https://www.linkedin.com/in/someshghaturle/](https://www.linkedin.com/in/someshghaturle/)Color=white)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸŒŸ Overview

AgenTech Research Hub is a powerful AI-driven research platform that performs **real internet searches** across multiple sources including DuckDuckGo, Wikipedia, Reddit, and GitHub. Built with FastAPI and featuring a modern web interface, it provides intelligent topic detection, multi-source research aggregation, and professional reporting.

## âœ¨ Key Features

- ğŸ” **Real Internet Search**: Actual web scraping from multiple sources (not mock data)
- ğŸ¯ **Intelligent Topic Detection**: Automatically categorizes research queries
- ğŸŒ **Multi-Source Research**: DuckDuckGo, Wikipedia, Reddit, GitHub integration
- ğŸ“Š **Quality Scoring**: Relevance and credibility assessment of sources
- ğŸ¨ **Professional Web UI**: Modern, responsive interface with blue corporate theme
- ğŸ³ **Docker Ready**: Complete containerization with nginx load balancing
- âš¡ **FastAPI Backend**: High-performance async API with automatic documentation
- ğŸ”„ **CORS Support**: Cross-origin requests handled seamlessly

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd "AgenTech Research Hub"

# Start with Docker Compose
docker-compose up -d

# Access the application
# Web UI: http://localhost:3000
# API Docs: http://localhost:8000/docs
# Health Check: http://localhost:3000/health
```

### Option 2: Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Start the API server
python api_server.py

# Open web UI
open web-ui/index.html
```

## ğŸ—ï¸ System Architecture

```mermaid
flowchart TB
    subgraph "User Interface"
        UI[ğŸŒ Web Interface<br/>HTML/CSS/JavaScript]
        USER[ğŸ‘¤ User Query Input]
    end
    
    subgraph "Docker Environment"
        subgraph "Nginx Proxy"
            NGINX[ğŸ”„ Nginx Reverse Proxy<br/>Port 80]
        end
        
        subgraph "API Layer"
            API[ğŸš€ FastAPI Backend<br/>Port 8000]
            HEALTH[ğŸ’š Health Endpoints]
            RESEARCH[ğŸ” Research Endpoints]
        end
        
        subgraph "Core Intelligence"
            AGENT[ğŸ¤– Research Agent<br/>AI-Powered Analysis]
            SEARCH[ğŸŒ Multi-Source Search Engine]
        end
        
        subgraph "External Data Sources"
            DUCK[ğŸ¦† DuckDuckGo Search]
            WIKI[ğŸ“š Wikipedia API]
            REDDIT[ğŸ’¬ Reddit API]
            GITHUB[ğŸ™ GitHub Search]
        end
        
        subgraph "Data Processing"
            SCORER[ğŸ“Š Quality Scoring System]
            CACHE[âš¡ Redis Cache]
            FILTER[ğŸ¯ Content Filtering]
        end
    end
    
    %% User Flow
    USER --> UI
    UI --> NGINX
    NGINX --> API
    
    %% API Processing
    API --> HEALTH
    API --> RESEARCH
    RESEARCH --> AGENT
    
    %% Research Flow
    AGENT --> SEARCH
    SEARCH --> DUCK
    SEARCH --> WIKI
    SEARCH --> REDDIT
    SEARCH --> GITHUB
    
    %% Data Processing Flow
    DUCK --> SCORER
    WIKI --> SCORER
    REDDIT --> SCORER
    GITHUB --> SCORER
    
    SCORER --> FILTER
    FILTER --> CACHE
    CACHE --> AGENT
    
    %% Response Flow
    AGENT --> RESEARCH
    RESEARCH --> API
    API --> NGINX
    NGINX --> UI
    UI --> USER
    
    %% Styling
    classDef userClass fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef apiClass fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef agentClass fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef dataClass fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef processClass fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    
    class USER,UI userClass
    class NGINX,API,HEALTH,RESEARCH apiClass
    class AGENT,SEARCH agentClass
    class DUCK,WIKI,REDDIT,GITHUB dataClass
    class SCORER,CACHE,FILTER processClass
```

## ğŸ”„ Research Workflow

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ User
    participant UI as ğŸŒ Web Interface
    participant API as ğŸš€ FastAPI
    participant Agent as ğŸ¤– Research Agent
    participant Search as ğŸ” Search Engine
    participant Sources as ğŸŒ External APIs
    participant Cache as âš¡ Redis Cache
    
    User->>UI: Enter research query
    UI->>API: POST /api/research
    API->>Agent: Process research request
    
    Agent->>Cache: Check for cached results
    alt Cache Hit
        Cache-->>Agent: Return cached data
    else Cache Miss
        Agent->>Search: Initiate multi-source search
        
        par Parallel Search
            Search->>Sources: DuckDuckGo API
            Search->>Sources: Wikipedia API
            Search->>Sources: Reddit API
            Search->>Sources: GitHub API
        end
        
        Sources-->>Search: Raw search results
        Search->>Search: Quality scoring & filtering
        Search->>Cache: Store processed results
        Search-->>Agent: Return ranked results
    end
    
    Agent->>Agent: Generate comprehensive analysis
    Agent-->>API: Research insights
    API-->>UI: JSON response
    UI-->>User: Display formatted results
```

### Components

- **FastAPI Backend**: Handles research requests and web scraping
- **Nginx Proxy**: Serves static files and proxies API calls
- **Web UI**: Modern JavaScript interface with auto-detection
- **Redis Cache**: Optional caching layer for improved performance

## ğŸ“Š Search Sources

| Source | Purpose | Data Type |
|--------|---------|-----------|
| **DuckDuckGo** | General web search | Instant answers, web results |
| **Wikipedia** | Authoritative content | Encyclopedia articles |
| **Reddit** | Community insights | Discussions, trends |
| **GitHub** | Technical content | Code repositories, documentation |

## ğŸŒ API Endpoints

### Core Endpoints

```bash
# Health check
GET /health

# Research endpoint
POST /research
{
  "query": "your research topic",
  "context": {"max_results": 10}
}

# System status
GET /status
```

### Response Format

```json
{
  "success": true,
  "query": "machine learning trends 2025",
  "sources_found": 8,
  "sources": [
    {
      "source_type": "SEARCH_ENGINE",
      "title": "ML Trends 2025",
      "url": "https://example.com",
      "snippet": "Latest developments...",
      "relevance_score": 0.9
    }
  ],
  "summary": "Research summary...",
  "quality_score": 0.85
}
```

## ğŸ“ Project Structure

```text
AgenTech Research Hub/
â”œâ”€â”€ ğŸ“„ README.md                    # Project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore patterns
â”œâ”€â”€ ğŸ“„ .env.example                 # Environment variables template
â”œâ”€â”€ ğŸ“„ api_server.py                # FastAPI main application (entry point)
â”œâ”€â”€ ğŸ³ Dockerfile                   # Container configuration
â”œâ”€â”€ ï¿½ docker-compose.yml           # Multi-service Docker setup
â”œâ”€â”€ âš™ï¸ nginx.conf                   # Nginx reverse proxy configuration
â”œâ”€â”€ ğŸ§ª test_docker.sh               # Docker testing script
â”œâ”€â”€ ğŸ“„ start_server.sh              # Server startup script
â”œâ”€â”€ ğŸ“„ stop_server.sh               # Server shutdown script
â”œâ”€â”€ ï¿½ğŸ“ src/                         # Main source code
â”‚   â”œâ”€â”€ ï¿½ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ ğŸ“„ main.py                  # Alternative main entry point
â”‚   â”œâ”€â”€ ï¿½ğŸ“ agents/                  # AI Agent implementations
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ base_agent.py        # Base agent class
â”‚   â”‚   â””â”€â”€ ğŸ“„ researcher_agent.py  # Research agent with real web search
â”‚   â”œâ”€â”€ ğŸ“ api/                     # API route definitions
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          
â”‚   â”‚   â””â”€â”€ ğŸ“„ routes.py            # FastAPI route handlers
â”‚   â”œâ”€â”€ ğŸ“ core/                    # Core application logic
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          
â”‚   â”‚   â””â”€â”€ ğŸ“„ base.py              # Base application classes
â”‚   â”œâ”€â”€ ğŸ“ config/                  # Configuration management
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          
â”‚   â”‚   â””â”€â”€ ğŸ“„ settings.py          # Application settings
â”‚   â”œâ”€â”€ ğŸ“ crews/                   # Multi-agent crew definitions
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          
â”‚   â”‚   â””â”€â”€ ğŸ“„ research_crew.py     # Research crew coordination
â”‚   â”œâ”€â”€ ğŸ“ utils/                   # Utility functions
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          
â”‚   â”‚   â””â”€â”€ ğŸ“„ helpers.py           # Helper functions
â”‚   â””â”€â”€ ğŸ“ workflows/               # Workflow definitions
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py          
â”‚       â””â”€â”€ ğŸ“„ research_workflow.py # Research workflow logic
â”œâ”€â”€ ğŸ“ web-ui/                      # Frontend web interface
â”‚   â”œâ”€â”€ ğŸ“„ index.html               # Main web interface (with inline CSS)
â”‚   â”œâ”€â”€ ğŸ“„ app.js                   # JavaScript application logic
â”‚   â””â”€â”€ ğŸ“„ test-connection.html     # Connection testing page
â”œâ”€â”€ ğŸ“ tests/                       # Test suite
â”‚   â”œâ”€â”€ ï¿½ __init__.py              
â”‚   â”œâ”€â”€ ğŸ“„ conftest.py              # Pytest configuration
â”‚   â”œâ”€â”€ ï¿½ test_main.py             # Main application tests
â”‚   â””â”€â”€ ğŸ“ data/                    # Test data files
â”œâ”€â”€ ğŸ“ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ ğŸ“„ setup.py                 # Setup and installation script
â”‚   â”œâ”€â”€ ğŸ“„ run.py                   # Application runner
â”‚   â””â”€â”€ ğŸ“„ demo.py                  # Demo and examples
â”œâ”€â”€ ğŸ“ examples/                    # Usage examples
â”‚   â””â”€â”€ ğŸ“„ custom_research_queries.py # Research query examples
â”œâ”€â”€ ğŸ“ docs/                        # Additional documentation
â”‚   â””â”€â”€ ï¿½ project_documentation.md # Technical documentation
â”œâ”€â”€ ğŸ“ data/                        # Data storage directories
â”‚   â”œâ”€â”€ ğŸ“ cache/                   # Cached data
â”‚   â”œâ”€â”€ ğŸ“ checkpoints/             # Model checkpoints
â”‚   â”œâ”€â”€ ğŸ“ logs/                    # Application logs
â”‚   â”œâ”€â”€ ğŸ“ models/                  # AI model storage
â”‚   â”œâ”€â”€ ğŸ“ outputs/                 # Generated outputs
â”‚   â”œâ”€â”€ ğŸ“ processed/               # Processed data
â”‚   â”œâ”€â”€ ğŸ“ raw/                     # Raw input data
â”‚   â””â”€â”€ ï¿½ vector_db/               # Vector database storage
â””â”€â”€ ğŸ“ logs/                        # Runtime logs (Docker)
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Test API endpoints
curl http://localhost:8000/health
curl -X POST http://localhost:8000/research \
  -H "Content-Type: application/json" \
  -d '{"query": "artificial intelligence"}'

# Docker testing
./test_docker.sh
```

## âš™ï¸ Configuration

### Environment Variables

```bash
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO

# Optional: Add API keys for enhanced functionality
OPENAI_API_KEY=your-key-here
ANTHROPIC_API_KEY=your-key-here
```

### Docker Configuration

```yaml
# docker-compose.yml
services:
  agentech-api:     # FastAPI backend on port 8000
  agentech-webui:   # Nginx frontend on port 3000  
  redis:            # Optional caching on port 6379
```

## ğŸ”§ Development

### Adding New Search Sources

1. Implement search method in `src/agents/researcher_agent.py`
2. Add to the `_web_search` method source list
3. Handle rate limiting and error cases
4. Update tests and documentation

### Customizing the UI

1. Modify `web-ui/index.html` for structure
2. Update `web-ui/app.js` for functionality
3. Customize `web-ui/styles.css` for styling
4. Test responsiveness across devices

## ğŸš¨ Troubleshooting

### Common Issues

**Port conflicts:**

```bash
# Check what's using the ports
lsof -i :3000
lsof -i :8000

# Kill conflicting processes
sudo kill -9 <PID>
```

**Docker issues:**

```bash
# Reset Docker setup
docker-compose down
docker system prune -f
docker-compose up --build -d
```

**API connection fails:**

- Check if Docker daemon is running
- Verify nginx proxy configuration
- Check container logs: `docker-compose logs`

## ğŸ“ˆ Performance

- **Response Time**: < 3 seconds for typical research queries
- **Concurrent Users**: Supports multiple simultaneous requests
- **Search Sources**: 4+ integrated sources with intelligent fallbacks
- **Cache Support**: Redis integration for improved performance

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes and add tests
4. Commit changes: `git commit -am 'Add feature'`
5. Push to branch: `git push origin feature-name`
6. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”— Links

- **Web UI**: <http://localhost:3000>
- **API Documentation**: <http://localhost:8000/docs>
- **Health Monitor**: <http://localhost:3000/health>

---

## ï¿½â€ğŸ’» Author & License

All code and content in this repository is for educational and personal use.

**Somesh Ramesh Ghaturle**  
MS in Data Science, Pace University

---

### Built with â¤ï¸ using FastAPI, Docker, and Modern Web Technologies
